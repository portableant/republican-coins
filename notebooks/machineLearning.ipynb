{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202a7639",
   "metadata": {},
   "source": [
    "# Proof of concept Machine Learning model for coin classification\n",
    "\n",
    "I tried to do a very simple proof of concept using the pulled out dataset of coin images. The goal was to classify the coins based on their visual features. This is going to use labelled images that have been broken into obverse and reverse sides and attached to a type where available. \n",
    "\n",
    "First make sure you have OpenCV installed and ready to use. The code samples below are juts going to show to split the images from the small dataset into their two sides, ready to use. The full model I used has been trained on all the images, and that will be used later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5881eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from opencv-python) (2.0.2)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a32f9",
   "metadata": {},
   "source": [
    "Let's now split the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e7d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output folder: './data/split_images'\n",
      "Found 78 files in './data/downloaded_images'. Starting to process...\n",
      "Successfully split and saved 'HAMP-B3BE56_67ab8670dfebc.jpg' into 'HAMP-B3BE56_67ab8670dfebc_obverse.jpg' and 'HAMP-B3BE56_67ab8670dfebc_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-DF77F7_67d402122a7df.jpg' into 'BERK-DF77F7_67d402122a7df_obverse.jpg' and 'BERK-DF77F7_67d402122a7df_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-E9366E_67ce937b6b569.jpg' into 'SUR-E9366E_67ce937b6b569_obverse.jpg' and 'SUR-E9366E_67ce937b6b569_reverse.jpg'.\n",
      "Successfully split and saved 'SF-27EB9B_685034acf0128.jpg' into 'SF-27EB9B_685034acf0128_obverse.jpg' and 'SF-27EB9B_685034acf0128_reverse.jpg'.\n",
      "Successfully split and saved 'WMID-09A2CE_6819dbda61c89.jpg' into 'WMID-09A2CE_6819dbda61c89_obverse.jpg' and 'WMID-09A2CE_6819dbda61c89_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-ADE232_67dade99159e6.jpg' into 'SUR-ADE232_67dade99159e6_obverse.jpg' and 'SUR-ADE232_67dade99159e6_reverse.jpg'.\n",
      "Successfully split and saved 'SWYOR-91E15B_6862c07573466.jpg' into 'SWYOR-91E15B_6862c07573466_obverse.jpg' and 'SWYOR-91E15B_6862c07573466_reverse.jpg'.\n",
      "Successfully split and saved 'OXON-208026_6812096783214.jpg' into 'OXON-208026_6812096783214_obverse.jpg' and 'OXON-208026_6812096783214_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-8F4653_687611bc28843.jpg' into 'BERK-8F4653_687611bc28843_obverse.jpg' and 'BERK-8F4653_687611bc28843_reverse.jpg'.\n",
      "Successfully split and saved 'ESS-F092BB_6842e05912ec8.jpg' into 'ESS-F092BB_6842e05912ec8_obverse.jpg' and 'ESS-F092BB_6842e05912ec8_reverse.jpg'.\n",
      "Successfully split and saved 'YORYM-493963_68a59124800a5.jpg' into 'YORYM-493963_68a59124800a5_obverse.jpg' and 'YORYM-493963_68a59124800a5_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-DF9682_67d410eb867a0.jpg' into 'BERK-DF9682_67d410eb867a0_obverse.jpg' and 'BERK-DF9682_67d410eb867a0_reverse.jpg'.\n",
      "Successfully split and saved 'WREX-88411A_67c8865c65ca8.jpg' into 'WREX-88411A_67c8865c65ca8_obverse.jpg' and 'WREX-88411A_67c8865c65ca8_reverse.jpg'.\n",
      "Successfully split and saved 'YORYM-5DC6ED_68501ee5d96eb.jpg' into 'YORYM-5DC6ED_68501ee5d96eb_obverse.jpg' and 'YORYM-5DC6ED_68501ee5d96eb_reverse.jpg'.\n",
      "Successfully split and saved 'HAMP-905009_68590bb613a11.jpg' into 'HAMP-905009_68590bb613a11_obverse.jpg' and 'HAMP-905009_68590bb613a11_reverse.jpg'.\n",
      "Successfully split and saved 'SF-683A10_68762c8c57dc5.jpg' into 'SF-683A10_68762c8c57dc5_obverse.jpg' and 'SF-683A10_68762c8c57dc5_reverse.jpg'.\n",
      "Successfully split and saved 'WAW-34F1AE_68239793630e5.jpg' into 'WAW-34F1AE_68239793630e5_obverse.jpg' and 'WAW-34F1AE_68239793630e5_reverse.jpg'.\n",
      "Successfully split and saved 'SF-3016DF_6853c3a9da387.jpg' into 'SF-3016DF_6853c3a9da387_obverse.jpg' and 'SF-3016DF_6853c3a9da387_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-5ECF7E_67a62003bc046.jpg' into 'SUR-5ECF7E_67a62003bc046_obverse.jpg' and 'SUR-5ECF7E_67a62003bc046_reverse.jpg'.\n",
      "Successfully split and saved 'SF-3F0350_67924ade8c170.jpg' into 'SF-3F0350_67924ade8c170_obverse.jpg' and 'SF-3F0350_67924ade8c170_reverse.jpg'.\n",
      "Successfully split and saved 'ESS-4D0B71_67a4d23fee25c.jpg' into 'ESS-4D0B71_67a4d23fee25c_obverse.jpg' and 'ESS-4D0B71_67a4d23fee25c_reverse.jpg'.\n",
      "Successfully split and saved 'KENT-55AA42_68655af514f86.jpg' into 'KENT-55AA42_68655af514f86_obverse.jpg' and 'KENT-55AA42_68655af514f86_reverse.jpg'.\n",
      "Successfully split and saved 'WAW-932FCA_685a792a0d8a2.jpg' into 'WAW-932FCA_685a792a0d8a2_obverse.jpg' and 'WAW-932FCA_685a792a0d8a2_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-38C727_67b1f99f6ddff.jpg' into 'BERK-38C727_67b1f99f6ddff_obverse.jpg' and 'BERK-38C727_67b1f99f6ddff_reverse.jpg'.\n",
      "Successfully split and saved 'ESS-407D4A_67e5327a1e8e4.jpg' into 'ESS-407D4A_67e5327a1e8e4_obverse.jpg' and 'ESS-407D4A_67e5327a1e8e4_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-4C2E85_6874db2471a8b.jpg' into 'SUR-4C2E85_6874db2471a8b_obverse.jpg' and 'SUR-4C2E85_6874db2471a8b_reverse.jpg'.\n",
      "Successfully split and saved 'YORYM-0D8600_6800dc2d7ddcc.jpg' into 'YORYM-0D8600_6800dc2d7ddcc_obverse.jpg' and 'YORYM-0D8600_6800dc2d7ddcc_reverse.jpg'.\n",
      "Successfully split and saved 'OXON-DB458E_682db7cac04ab.jpg' into 'OXON-DB458E_682db7cac04ab_obverse.jpg' and 'OXON-DB458E_682db7cac04ab_reverse.jpg'.\n",
      "Successfully split and saved 'SF-5C3305_68664e4d52a71.jpg' into 'SF-5C3305_68664e4d52a71_obverse.jpg' and 'SF-5C3305_68664e4d52a71_reverse.jpg'.\n",
      "Successfully split and saved 'DENO-72FB23_687cfdc91d174.jpg' into 'DENO-72FB23_687cfdc91d174_obverse.jpg' and 'DENO-72FB23_687cfdc91d174_reverse.jpg'.\n",
      "Successfully split and saved 'SUSS-AA2E32_67ed797c5c3de.jpg' into 'SUSS-AA2E32_67ed797c5c3de_obverse.jpg' and 'SUSS-AA2E32_67ed797c5c3de_reverse.jpg'.\n",
      "Successfully split and saved 'ESS-511D9B_6808afa78fbc2.jpg' into 'ESS-511D9B_6808afa78fbc2_obverse.jpg' and 'ESS-511D9B_6808afa78fbc2_reverse.jpg'.\n",
      "Successfully split and saved 'YORYM-FD95AF_678640a7a84d7.jpg' into 'YORYM-FD95AF_678640a7a84d7_obverse.jpg' and 'YORYM-FD95AF_678640a7a84d7_reverse.jpg'.\n",
      "Successfully split and saved 'LIN-561371_68a6c5f4ac9a4.jpg' into 'LIN-561371_68a6c5f4ac9a4_obverse.jpg' and 'LIN-561371_68a6c5f4ac9a4_reverse.jpg'.\n",
      "Successfully split and saved 'SF-D4E9BC_67e3f56b5fea7.jpg' into 'SF-D4E9BC_67e3f56b5fea7_obverse.jpg' and 'SF-D4E9BC_67e3f56b5fea7_reverse.jpg'.\n",
      "Successfully split and saved 'LVPL-167290_685ec780e1c94.jpg' into 'LVPL-167290_685ec780e1c94_obverse.jpg' and 'LVPL-167290_685ec780e1c94_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-8F1AC6_687612a110ec4.jpg' into 'BERK-8F1AC6_687612a110ec4_obverse.jpg' and 'BERK-8F1AC6_687612a110ec4_reverse.jpg'.\n",
      "Successfully split and saved 'YORYM-E58340_68133f0a9754d.jpg' into 'YORYM-E58340_68133f0a9754d_obverse.jpg' and 'YORYM-E58340_68133f0a9754d_reverse.jpg'.\n",
      "Successfully split and saved 'WREX-58B050_67c58c628913d.jpg' into 'WREX-58B050_67c58c628913d_obverse.jpg' and 'WREX-58B050_67c58c628913d_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-31162B_682357991bda0.jpg' into 'SUR-31162B_682357991bda0_obverse.jpg' and 'SUR-31162B_682357991bda0_reverse.jpg'.\n",
      "Successfully split and saved 'WREX-37BFE7_67a37ea1de9b0.jpg' into 'WREX-37BFE7_67a37ea1de9b0_obverse.jpg' and 'WREX-37BFE7_67a37ea1de9b0_reverse.jpg'.\n",
      "Successfully split and saved 'WMID-C303A6_686d16ce9fc4d.jpg' into 'WMID-C303A6_686d16ce9fc4d_obverse.jpg' and 'WMID-C303A6_686d16ce9fc4d_reverse.jpg'.\n",
      "Successfully split and saved 'SF-B16CF6_68652e7cada09.jpg' into 'SF-B16CF6_68652e7cada09_obverse.jpg' and 'SF-B16CF6_68652e7cada09_reverse.jpg'.\n",
      "Successfully split and saved 'SWYOR-0BFE82_67b4ca85825c8.jpg' into 'SWYOR-0BFE82_67b4ca85825c8_obverse.jpg' and 'SWYOR-0BFE82_67b4ca85825c8_reverse.jpg'.\n",
      "Successfully split and saved 'OXON-B1F617_681b278a218b6.jpg' into 'OXON-B1F617_681b278a218b6_obverse.jpg' and 'OXON-B1F617_681b278a218b6_reverse.jpg'.\n",
      "Successfully split and saved 'ESS-34658D_67b3478a2d5fe.jpg' into 'ESS-34658D_67b3478a2d5fe_obverse.jpg' and 'ESS-34658D_67b3478a2d5fe_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-69D94C_67e6a48c4b5e5.jpg' into 'SUR-69D94C_67e6a48c4b5e5_obverse.jpg' and 'SUR-69D94C_67e6a48c4b5e5_reverse.jpg'.\n",
      "Successfully split and saved 'OXON-3D0903_67e85c784f1e2.jpg' into 'OXON-3D0903_67e85c784f1e2_obverse.jpg' and 'OXON-3D0903_67e85c784f1e2_reverse.jpg'.\n",
      "Successfully split and saved 'IOW-C4A261_67bc6aaac34d7.jpg' into 'IOW-C4A261_67bc6aaac34d7_obverse.jpg' and 'IOW-C4A261_67bc6aaac34d7_reverse.jpg'.\n",
      "Successfully split and saved 'BUC-134FE1_68513593a9599.jpg' into 'BUC-134FE1_68513593a9599_obverse.jpg' and 'BUC-134FE1_68513593a9599_reverse.jpg'.\n",
      "Successfully split and saved 'SWYOR-804741_67f8195d8476e.jpg' into 'SWYOR-804741_67f8195d8476e_obverse.jpg' and 'SWYOR-804741_67f8195d8476e_reverse.jpg'.\n",
      "Successfully split and saved 'LEIC-4E87FF_6824e8b8ea619.jpg' into 'LEIC-4E87FF_6824e8b8ea619_obverse.jpg' and 'LEIC-4E87FF_6824e8b8ea619_reverse.jpg'.\n",
      "Successfully split and saved 'WMID-3E72F3_67ee654d9a97f.jpg' into 'WMID-3E72F3_67ee654d9a97f_obverse.jpg' and 'WMID-3E72F3_67ee654d9a97f_reverse.jpg'.\n",
      "Successfully split and saved 'NARC-B4DFE0_679b4e55970df.jpg' into 'NARC-B4DFE0_679b4e55970df_obverse.jpg' and 'NARC-B4DFE0_679b4e55970df_reverse.jpg'.\n",
      "Successfully split and saved 'SUSS-A09294_67ab6a9da023e.jpg' into 'SUSS-A09294_67ab6a9da023e_obverse.jpg' and 'SUSS-A09294_67ab6a9da023e_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-609809_688773ef6844e.jpg' into 'SUR-609809_688773ef6844e_obverse.jpg' and 'SUR-609809_688773ef6844e_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-DF7E0C_67d406f5c423c.jpg' into 'BERK-DF7E0C_67d406f5c423c_obverse.jpg' and 'BERK-DF7E0C_67d406f5c423c_reverse.jpg'.\n",
      "Successfully split and saved 'SWYOR-425A1E_6810b382a7f02.jpg' into 'SWYOR-425A1E_6810b382a7f02_obverse.jpg' and 'SWYOR-425A1E_6810b382a7f02_reverse.jpg'.\n",
      "Successfully split and saved 'WILT-706C7C_67c9b7d769986.jpg' into 'WILT-706C7C_67c9b7d769986_obverse.jpg' and 'WILT-706C7C_67c9b7d769986_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-0D5C1B_67b1f8b69a389.jpg' into 'BERK-0D5C1B_67b1f8b69a389_obverse.jpg' and 'BERK-0D5C1B_67b1f8b69a389_reverse.jpg'.\n",
      "Successfully split and saved 'BUC-D0BC14_67fd0c3cf3b68.jpg' into 'BUC-D0BC14_67fd0c3cf3b68_obverse.jpg' and 'BUC-D0BC14_67fd0c3cf3b68_reverse.jpg'.\n",
      "Successfully split and saved 'GAT-06A665_68b06c8915771.jpg' into 'GAT-06A665_68b06c8915771_obverse.jpg' and 'GAT-06A665_68b06c8915771_reverse.jpg'.\n",
      "Successfully split and saved 'SUSS-CA1B88_67aca1d89c7aa.jpg' into 'SUSS-CA1B88_67aca1d89c7aa_obverse.jpg' and 'SUSS-CA1B88_67aca1d89c7aa_reverse.jpg'.\n",
      "Successfully split and saved 'DENO-03EA0C_687cfb5b303d4.jpg' into 'DENO-03EA0C_687cfb5b303d4_obverse.jpg' and 'DENO-03EA0C_687cfb5b303d4_reverse.jpg'.\n",
      "Successfully split and saved 'OXON-347195_67ac7afbd0b97.jpg' into 'OXON-347195_67ac7afbd0b97_obverse.jpg' and 'OXON-347195_67ac7afbd0b97_reverse.jpg'.\n",
      "Successfully split and saved 'WMID-3AE27B_67f3b24532d6b.jpg' into 'WMID-3AE27B_67f3b24532d6b_obverse.jpg' and 'WMID-3AE27B_67f3b24532d6b_reverse.jpg'.\n",
      "Successfully split and saved 'SF-B2A999_6825f6f19caa2.jpg' into 'SF-B2A999_6825f6f19caa2_obverse.jpg' and 'SF-B2A999_6825f6f19caa2_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-131C30_67d132bf08516.jpg' into 'SUR-131C30_67d132bf08516_obverse.jpg' and 'SUR-131C30_67d132bf08516_reverse.jpg'.\n",
      "Successfully split and saved 'WREX-C9E614_67bc9efb2b4ae.jpg' into 'WREX-C9E614_67bc9efb2b4ae_obverse.jpg' and 'WREX-C9E614_67bc9efb2b4ae_reverse.jpg'.\n",
      "Successfully split and saved 'SF-3505CE_6853c190126a2.jpg' into 'SF-3505CE_6853c190126a2_obverse.jpg' and 'SF-3505CE_6853c190126a2_reverse.jpg'.\n",
      "Successfully split and saved 'SUR-8C2F5D_6799e8b326ac5.jpg' into 'SUR-8C2F5D_6799e8b326ac5_obverse.jpg' and 'SUR-8C2F5D_6799e8b326ac5_reverse.jpg'.\n",
      "Successfully split and saved 'SOM-DD47B2_67bd978155775.jpg' into 'SOM-DD47B2_67bd978155775_obverse.jpg' and 'SOM-DD47B2_67bd978155775_reverse.jpg'.\n",
      "Successfully split and saved 'LVPL-AB479B_680b83e81ba0f.jpg' into 'LVPL-AB479B_680b83e81ba0f_obverse.jpg' and 'LVPL-AB479B_680b83e81ba0f_reverse.jpg'.\n",
      "Successfully split and saved 'SF-C00464_686fa5b01dd78.jpg' into 'SF-C00464_686fa5b01dd78_obverse.jpg' and 'SF-C00464_686fa5b01dd78_reverse.jpg'.\n",
      "Successfully split and saved 'BERK-0D63F7_67b1f92ac8f97.jpg' into 'BERK-0D63F7_67b1f92ac8f97_obverse.jpg' and 'BERK-0D63F7_67b1f92ac8f97_reverse.jpg'.\n",
      "Successfully split and saved 'SUSS-1967B5_6762be71a5cf4.jpg' into 'SUSS-1967B5_6762be71a5cf4_obverse.jpg' and 'SUSS-1967B5_6762be71a5cf4_reverse.jpg'.\n",
      "Successfully split and saved 'GLO-FD8072_6838808c34eb6.jpg' into 'GLO-FD8072_6838808c34eb6_obverse.jpg' and 'GLO-FD8072_6838808c34eb6_reverse.jpg'.\n",
      "Successfully split and saved 'BUC-6E2C1C_67c713b28f8e7.jpg' into 'BUC-6E2C1C_67c713b28f8e7_obverse.jpg' and 'BUC-6E2C1C_67c713b28f8e7_reverse.jpg'.\n",
      "\n",
      "Image splitting process complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# --- Configuration ---\n",
    "# The folder where your combined coin images are located\n",
    "input_folder = './data/downloaded_images'\n",
    "# The folder where the split images will be saved\n",
    "output_folder = './data/split_images'\n",
    "\n",
    "# --- Main Script ---\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"Created output folder: '{output_folder}'\")\n",
    "\n",
    "# Get a list of all files in the input folder\n",
    "all_files = os.listdir(input_folder)\n",
    "\n",
    "print(f\"Found {len(all_files)} files in '{input_folder}'. Starting to process...\")\n",
    "\n",
    "for filename in all_files:\n",
    "    # Check if the file is a common image format\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        img = cv2.imread(file_path)\n",
    "\n",
    "        # Check if the image was loaded correctly\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image '{filename}'. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Get the dimensions of the image\n",
    "        height, width, _ = img.shape\n",
    "        \n",
    "        # Check if the image is wide enough to be split\n",
    "        if width <= 10:  # A small threshold to prevent errors on tiny files\n",
    "            print(f\"Warning: Image '{filename}' is too narrow to split. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Split the image into two halves\n",
    "        split_point = width // 2\n",
    "        obverse_img = img[:, :split_point]\n",
    "        reverse_img = img[:, split_point:]\n",
    "        \n",
    "        # Create new filenames for the split images\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        obverse_filename = f\"{base_name}_obverse{ext}\"\n",
    "        reverse_filename = f\"{base_name}_reverse{ext}\"\n",
    "        \n",
    "        # Define the full paths to save the new images\n",
    "        obverse_path = os.path.join(output_folder, obverse_filename)\n",
    "        reverse_path = os.path.join(output_folder, reverse_filename)\n",
    "\n",
    "        # Save the new images\n",
    "        cv2.imwrite(obverse_path, obverse_img)\n",
    "        cv2.imwrite(reverse_path, reverse_img)\n",
    "        \n",
    "        print(f\"Successfully split and saved '{filename}' into '{obverse_filename}' and '{reverse_filename}'.\")\n",
    "\n",
    "print(\"\\nImage splitting process complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0d703",
   "metadata": {},
   "source": [
    "Now the images are ready, you can train the model. This will be a very simple proof of concept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a89c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "Requirement already satisfied: tensorflow in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (2.20.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: rich in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard~=2.20.0->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.20.0->tensorflow) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/dejp3/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.6.1 scipy-1.13.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy tensorflow scikit-learn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea504ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 files in the directory.\n",
      "No matching label found for image: WMID-09A2CE_6819dbda61c89_obverse.jpg\n",
      "No matching label found for image: SF-C00464_686fa5b01dd78_reverse.jpg\n",
      "No matching label found for image: SUR-ADE232_67dade99159e6_reverse.jpg\n",
      "No matching label found for image: WREX-88411A_67c8865c65ca8_obverse.jpg\n",
      "No matching label found for image: SF-3016DF_6853c3a9da387_obverse.jpg\n",
      "No matching label found for image: YORYM-5DC6ED_68501ee5d96eb_reverse.jpg\n",
      "No matching label found for image: SF-B2A999_6825f6f19caa2_reverse.jpg\n",
      "No matching label found for image: SF-27EB9B_685034acf0128_reverse.jpg\n",
      "No matching label found for image: BUC-134FE1_68513593a9599_obverse.jpg\n",
      "No matching label found for image: SF-3505CE_6853c190126a2_reverse.jpg\n",
      "No matching label found for image: GAT-06A665_68b06c8915771_obverse.jpg\n",
      "No matching label found for image: BUC-D0BC14_67fd0c3cf3b68_obverse.jpg\n",
      "No matching label found for image: OXON-B1F617_681b278a218b6_reverse.jpg\n",
      "No matching label found for image: BERK-DF9682_67d410eb867a0_reverse.jpg\n",
      "No matching label found for image: WILT-706C7C_67c9b7d769986_obverse.jpg\n",
      "No matching label found for image: SUR-4C2E85_6874db2471a8b_obverse.jpg\n",
      "No matching label found for image: SUR-609809_688773ef6844e_reverse.jpg\n",
      "No matching label found for image: BUC-6E2C1C_67c713b28f8e7_obverse.jpg\n",
      "No matching label found for image: SOM-DD47B2_67bd978155775_reverse.jpg\n",
      "No matching label found for image: WAW-932FCA_685a792a0d8a2_obverse.jpg\n",
      "No matching label found for image: SUR-E9366E_67ce937b6b569_reverse.jpg\n",
      "No matching label found for image: SF-D4E9BC_67e3f56b5fea7_reverse.jpg\n",
      "No matching label found for image: OXON-208026_6812096783214_obverse.jpg\n",
      "No matching label found for image: YORYM-0D8600_6800dc2d7ddcc_obverse.jpg\n",
      "No matching label found for image: SF-683A10_68762c8c57dc5_reverse.jpg\n",
      "No matching label found for image: SWYOR-0BFE82_67b4ca85825c8_reverse.jpg\n",
      "No matching label found for image: DENO-72FB23_687cfdc91d174_obverse.jpg\n",
      "No matching label found for image: WMID-3E72F3_67ee654d9a97f_reverse.jpg\n",
      "No matching label found for image: LVPL-167290_685ec780e1c94_reverse.jpg\n",
      "No matching label found for image: ESS-34658D_67b3478a2d5fe_obverse.jpg\n",
      "No matching label found for image: YORYM-493963_68a59124800a5_reverse.jpg\n",
      "No matching label found for image: ESS-F092BB_6842e05912ec8_obverse.jpg\n",
      "No matching label found for image: HAMP-B3BE56_67ab8670dfebc_obverse.jpg\n",
      "No matching label found for image: GLO-FD8072_6838808c34eb6_reverse.jpg\n",
      "No matching label found for image: HAMP-905009_68590bb613a11_reverse.jpg\n",
      "No matching label found for image: SUR-5ECF7E_67a62003bc046_reverse.jpg\n",
      "No matching label found for image: SUR-8C2F5D_6799e8b326ac5_reverse.jpg\n",
      "No matching label found for image: ESS-511D9B_6808afa78fbc2_reverse.jpg\n",
      "No matching label found for image: SF-3F0350_67924ade8c170_obverse.jpg\n",
      "No matching label found for image: SUSS-A09294_67ab6a9da023e_obverse.jpg\n",
      "No matching label found for image: SUR-31162B_682357991bda0_reverse.jpg\n",
      "No matching label found for image: SF-5C3305_68664e4d52a71_reverse.jpg\n",
      "No matching label found for image: SF-B16CF6_68652e7cada09_reverse.jpg\n",
      "No matching label found for image: NARC-B4DFE0_679b4e55970df_obverse.jpg\n",
      "No matching label found for image: OXON-3D0903_67e85c784f1e2_reverse.jpg\n",
      "No matching label found for image: WREX-C9E614_67bc9efb2b4ae_reverse.jpg\n",
      "No matching label found for image: LEIC-4E87FF_6824e8b8ea619_obverse.jpg\n",
      "No matching label found for image: BERK-8F4653_687611bc28843_reverse.jpg\n",
      "No matching label found for image: BERK-DF77F7_67d402122a7df_obverse.jpg\n",
      "No matching label found for image: WAW-34F1AE_68239793630e5_obverse.jpg\n",
      "No matching label found for image: SWYOR-804741_67f8195d8476e_obverse.jpg\n",
      "No matching label found for image: SUSS-AA2E32_67ed797c5c3de_reverse.jpg\n",
      "No matching label found for image: WMID-3AE27B_67f3b24532d6b_reverse.jpg\n",
      "No matching label found for image: OXON-347195_67ac7afbd0b97_reverse.jpg\n",
      "No matching label found for image: SUR-609809_688773ef6844e_obverse.jpg\n",
      "No matching label found for image: WILT-706C7C_67c9b7d769986_reverse.jpg\n",
      "No matching label found for image: SUR-4C2E85_6874db2471a8b_reverse.jpg\n",
      "No matching label found for image: BUC-D0BC14_67fd0c3cf3b68_reverse.jpg\n",
      "No matching label found for image: GAT-06A665_68b06c8915771_reverse.jpg\n",
      "No matching label found for image: OXON-B1F617_681b278a218b6_obverse.jpg\n",
      "No matching label found for image: BERK-DF9682_67d410eb867a0_obverse.jpg\n",
      "No matching label found for image: SF-3505CE_6853c190126a2_obverse.jpg\n",
      "No matching label found for image: BUC-134FE1_68513593a9599_reverse.jpg\n",
      "No matching label found for image: SF-27EB9B_685034acf0128_obverse.jpg\n",
      "No matching label found for image: SF-B2A999_6825f6f19caa2_obverse.jpg\n",
      "No matching label found for image: YORYM-5DC6ED_68501ee5d96eb_obverse.jpg\n",
      "No matching label found for image: SF-3016DF_6853c3a9da387_reverse.jpg\n",
      "No matching label found for image: SUR-ADE232_67dade99159e6_obverse.jpg\n",
      "No matching label found for image: WREX-88411A_67c8865c65ca8_reverse.jpg\n",
      "No matching label found for image: WMID-09A2CE_6819dbda61c89_reverse.jpg\n",
      "No matching label found for image: SF-C00464_686fa5b01dd78_obverse.jpg\n",
      "No matching label found for image: SWYOR-0BFE82_67b4ca85825c8_obverse.jpg\n",
      "No matching label found for image: SF-683A10_68762c8c57dc5_obverse.jpg\n",
      "No matching label found for image: OXON-208026_6812096783214_reverse.jpg\n",
      "No matching label found for image: YORYM-0D8600_6800dc2d7ddcc_reverse.jpg\n",
      "No matching label found for image: SF-D4E9BC_67e3f56b5fea7_obverse.jpg\n",
      "No matching label found for image: SUR-E9366E_67ce937b6b569_obverse.jpg\n",
      "No matching label found for image: WAW-932FCA_685a792a0d8a2_reverse.jpg\n",
      "No matching label found for image: SOM-DD47B2_67bd978155775_obverse.jpg\n",
      "No matching label found for image: BUC-6E2C1C_67c713b28f8e7_reverse.jpg\n",
      "No matching label found for image: SUR-31162B_682357991bda0_obverse.jpg\n",
      "No matching label found for image: SUSS-A09294_67ab6a9da023e_reverse.jpg\n",
      "No matching label found for image: SF-3F0350_67924ade8c170_reverse.jpg\n",
      "No matching label found for image: ESS-511D9B_6808afa78fbc2_obverse.jpg\n",
      "No matching label found for image: SUR-8C2F5D_6799e8b326ac5_obverse.jpg\n",
      "No matching label found for image: HAMP-905009_68590bb613a11_obverse.jpg\n",
      "No matching label found for image: GLO-FD8072_6838808c34eb6_obverse.jpg\n",
      "No matching label found for image: SUR-5ECF7E_67a62003bc046_obverse.jpg\n",
      "No matching label found for image: HAMP-B3BE56_67ab8670dfebc_reverse.jpg\n",
      "No matching label found for image: ESS-F092BB_6842e05912ec8_reverse.jpg\n",
      "No matching label found for image: ESS-34658D_67b3478a2d5fe_reverse.jpg\n",
      "No matching label found for image: YORYM-493963_68a59124800a5_obverse.jpg\n",
      "No matching label found for image: LVPL-167290_685ec780e1c94_obverse.jpg\n",
      "No matching label found for image: DENO-72FB23_687cfdc91d174_reverse.jpg\n",
      "No matching label found for image: WMID-3E72F3_67ee654d9a97f_obverse.jpg\n",
      "No matching label found for image: OXON-347195_67ac7afbd0b97_obverse.jpg\n",
      "No matching label found for image: WMID-3AE27B_67f3b24532d6b_obverse.jpg\n",
      "No matching label found for image: SWYOR-804741_67f8195d8476e_reverse.jpg\n",
      "No matching label found for image: SUSS-AA2E32_67ed797c5c3de_obverse.jpg\n",
      "No matching label found for image: WAW-34F1AE_68239793630e5_reverse.jpg\n",
      "No matching label found for image: BERK-DF77F7_67d402122a7df_reverse.jpg\n",
      "No matching label found for image: LEIC-4E87FF_6824e8b8ea619_reverse.jpg\n",
      "No matching label found for image: BERK-8F4653_687611bc28843_obverse.jpg\n",
      "No matching label found for image: OXON-3D0903_67e85c784f1e2_obverse.jpg\n",
      "No matching label found for image: WREX-C9E614_67bc9efb2b4ae_obverse.jpg\n",
      "No matching label found for image: SF-B16CF6_68652e7cada09_obverse.jpg\n",
      "No matching label found for image: NARC-B4DFE0_679b4e55970df_reverse.jpg\n",
      "No matching label found for image: SF-5C3305_68664e4d52a71_obverse.jpg\n",
      "\n",
      "Loaded 48 images.\n",
      "\n",
      "Starting model training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejp3/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.0735 - loss: 3.5337 - val_accuracy: 0.0000e+00 - val_loss: 4.5626\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0559 - loss: 3.7118 - val_accuracy: 0.0000e+00 - val_loss: 3.2995\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0559 - loss: 3.1374 - val_accuracy: 0.0000e+00 - val_loss: 3.3148\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0839 - loss: 3.1010 - val_accuracy: 0.0000e+00 - val_loss: 3.3747\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1294 - loss: 3.0025 - val_accuracy: 0.0000e+00 - val_loss: 3.5123\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3076 - loss: 2.8408 - val_accuracy: 0.0000e+00 - val_loss: 3.9457\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1957 - loss: 2.6917 - val_accuracy: 0.0000e+00 - val_loss: 3.9305\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3673 - loss: 2.5037 - val_accuracy: 0.0000e+00 - val_loss: 3.8382\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5104 - loss: 2.2782 - val_accuracy: 0.0000e+00 - val_loss: 4.2384\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 1.9965 - val_accuracy: 0.0000e+00 - val_loss: 4.4767\n",
      "\n",
      "Evaluating model on test data...\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.0000e+00 - loss: 4.4767\n",
      "\n",
      "Test Accuracy: 0.00%\n",
      "\n",
      "Model saved to './models/coin_classifier_rrcID.keras'\n",
      "\n",
      "Label Mapping: {np.int64(0): 'rrc-237.1a', np.int64(1): 'rrc-241.1a', np.int64(2): 'rrc-270.1', np.int64(3): 'rrc-299.1b', np.int64(4): 'rrc-303.1', np.int64(5): 'rrc-321.1', np.int64(6): 'rrc-335.3a', np.int64(7): 'rrc-348.1', np.int64(8): 'rrc-353.1a', np.int64(9): 'rrc-374.1', np.int64(10): 'rrc-391.3', np.int64(11): 'rrc-392.1b', np.int64(12): 'rrc-412.1', np.int64(13): 'rrc-433.1', np.int64(14): 'rrc-448.1', np.int64(15): 'rrc-448.2', np.int64(16): 'rrc-449.1', np.int64(17): 'rrc-449.2', np.int64(18): 'rrc-465.4', np.int64(19): 'rrc-473.1', np.int64(20): 'rrc-494.21', np.int64(21): 'rrc-494.23', np.int64(22): 'rrc-544.14', np.int64(23): 'rrc-544.19'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def load_images_and_labels(image_dir, df, image_size=(128, 128), target_column='rrcID'):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses images, matching them to labels from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Path to the directory containing images.\n",
    "        df (pd.DataFrame): DataFrame with coin data and filenames.\n",
    "        image_size (tuple): Desired size for resizing images.\n",
    "        target_column (str): The column in the DataFrame to use for labels.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing (images_array, labels_array).\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Create a mapping from a sanitized filename to the target label\n",
    "    # This assumes 'filename' in the CSV matches the base part of the image filename.\n",
    "    df['filename_base'] = df['filename'].str.lower().str.replace('.jpg', '').str.replace('.jpeg', '')\n",
    "    label_map = df.set_index('filename_base')[target_column].to_dict()\n",
    "    \n",
    "    # List all files in the image directory\n",
    "    all_img_files = os.listdir(image_dir)\n",
    "    print(f\"Found {len(all_img_files)} files in the directory.\")\n",
    "    \n",
    "    for img_filename in all_img_files:\n",
    "        # Sanitize the image filename to match the format in the DataFrame\n",
    "        # Assumes the filename format is something like 'rrcID_obverse.jpg'\n",
    "        base_filename_parts = img_filename.lower().split('_')\n",
    "        if len(base_filename_parts) > 1 and (base_filename_parts[-1].endswith('.jpg') or base_filename_parts[-1].endswith('.jpeg')):\n",
    "            # The base filename is everything before the last underscore and file extension\n",
    "            base_filename = '_'.join(base_filename_parts[:-1])\n",
    "        else:\n",
    "            # Handle cases where there is no underscore, like 'rrcID.jpg'\n",
    "            base_filename = os.path.splitext(img_filename)[0].lower()\n",
    "            \n",
    "        # Check if this base filename exists in the mapping\n",
    "        if base_filename in label_map:\n",
    "            label = label_map[base_filename]\n",
    "            \n",
    "            if pd.isna(label):\n",
    "                print(f\"Skipping image '{img_filename}' due to NaN label.\")\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(image_dir, img_filename)\n",
    "            \n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read image at {img_path}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, image_size)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load image {img_filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"No matching label found for image: {img_filename}\")\n",
    "            \n",
    "    images = np.array(images, dtype='float32') / 255.0\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds a CNN model for multi-class classification.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "                  \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    image_directory = \"./data/split_images\"\n",
    "    csv_file_path = \"./data/reece1.csv\"\n",
    "    model_output_path = \"./models/coin_classifier_rrcID.keras\"\n",
    "\n",
    "    # --- Data Preprocessing and Loading ---\n",
    "    try:\n",
    "        df_labels = pd.read_csv(csv_file_path)\n",
    "        df_labels = df_labels.dropna(subset=['rrcID'])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The CSV file '{csv_file_path}' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    # Fit the encoder on the entire 'rrcID' column before dropping any data\n",
    "    le.fit(df_labels['rrcID'])\n",
    "    \n",
    "    # Now, load images and map to the encoded labels\n",
    "    X, y_labels = load_images_and_labels(image_directory, df_labels, target_column='rrcID')\n",
    "    print(f\"\\nLoaded {len(X)} images.\")\n",
    "    if len(X) == 0:\n",
    "        print(\"No images found or loaded. Please check your data directory and filename format.\")\n",
    "        exit()\n",
    "    \n",
    "    # Transform the loaded labels to their numerical representation\n",
    "    y_encoded = le.transform(y_labels)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # --- Model Building and Training ---\n",
    "    input_shape = X_train[0].shape\n",
    "    # Use the number of classes from the fitted LabelEncoder\n",
    "    num_classes = len(le.classes_) \n",
    "    \n",
    "    model = build_cnn_model(input_shape, num_classes)\n",
    "    \n",
    "    print(\"\\nStarting model training...\")\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # --- Evaluation and Saving ---\n",
    "    print(\"\\nEvaluating model on test data...\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    model.save(model_output_path)\n",
    "    print(f\"\\nModel saved to '{model_output_path}'\")\n",
    "    \n",
    "    label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "    print(\"\\nLabel Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88459f38",
   "metadata": {},
   "source": [
    "So, let's proceed with using the trained model to make predictions on new images. We're going to create a function that takes a directory of new images, preprocesses them, and then uses the model to predict their classes. I've added a few coins from CRRO to use for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2759ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction for images in './data/coins_to_classify'...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "--- Prediction Results ---\n",
      "File: large_00624497_001.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 15.87%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 14.96%)\n",
      "  - Predicted RRC ID: rrc-391.3 (Confidence: 13.63%)\n",
      "\n",
      "File: 1937.158.67.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 10.41%)\n",
      "  - Predicted RRC ID: rrc-391.3 (Confidence: 7.74%)\n",
      "  - Predicted RRC ID: rrc-270.1 (Confidence: 7.60%)\n",
      "\n",
      "File: 1974.26.48.rev.width175.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 10.04%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 7.56%)\n",
      "  - Predicted RRC ID: rrc-321.1 (Confidence: 6.75%)\n",
      "\n",
      "File: 1944.100.794.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 13.23%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 7.96%)\n",
      "  - Predicted RRC ID: rrc-321.1 (Confidence: 6.74%)\n",
      "\n",
      "File: SUR-4C2E85_6874db2471a8b.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 12.02%)\n",
      "  - Predicted RRC ID: rrc-241.1a (Confidence: 7.56%)\n",
      "  - Predicted RRC ID: rrc-473.1 (Confidence: 7.01%)\n",
      "\n",
      "File: small_00630874_001.jpg\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 11.19%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 11.09%)\n",
      "  - Predicted RRC ID: rrc-321.1 (Confidence: 8.18%)\n",
      "\n",
      "File: sitnam.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 10.97%)\n",
      "  - Predicted RRC ID: rrc-241.1a (Confidence: 8.37%)\n",
      "  - Predicted RRC ID: rrc-473.1 (Confidence: 7.21%)\n",
      "\n",
      "File: large_00625064_001.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 14.57%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 10.66%)\n",
      "  - Predicted RRC ID: rrc-321.1 (Confidence: 8.13%)\n",
      "\n",
      "File: 1995.11.1650.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 10.31%)\n",
      "  - Predicted RRC ID: rrc-241.1a (Confidence: 7.06%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 6.84%)\n",
      "\n",
      "File: 1947.2.175.rev.width175.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 9.52%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 8.85%)\n",
      "  - Predicted RRC ID: rrc-270.1 (Confidence: 8.16%)\n",
      "\n",
      "File: DenariusJuliusCasar270518JHF.jpg\n",
      "  - Predicted RRC ID: rrc-270.1 (Confidence: 11.31%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 8.97%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 8.89%)\n",
      "\n",
      "File: large_00630875_001.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 13.76%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 10.46%)\n",
      "  - Predicted RRC ID: rrc-391.3 (Confidence: 8.50%)\n",
      "\n",
      "File: large_01233074_001.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 11.09%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 9.32%)\n",
      "  - Predicted RRC ID: rrc-270.1 (Confidence: 6.42%)\n",
      "\n",
      "File: 1974.26.48.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 10.46%)\n",
      "  - Predicted RRC ID: rrc-321.1 (Confidence: 7.16%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 6.58%)\n",
      "\n",
      "File: large_00630874_001.jpg\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 12.56%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 11.81%)\n",
      "  - Predicted RRC ID: rrc-321.1 (Confidence: 8.31%)\n",
      "\n",
      "File: default.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 11.41%)\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 6.78%)\n",
      "  - Predicted RRC ID: rrc-241.1a (Confidence: 6.33%)\n",
      "\n",
      "File: large_00630755_001.jpg\n",
      "  - Predicted RRC ID: rrc-374.1 (Confidence: 14.27%)\n",
      "  - Predicted RRC ID: rrc-392.1b (Confidence: 12.17%)\n",
      "  - Predicted RRC ID: rrc-391.3 (Confidence: 11.52%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def predict_batch_of_images(model_path, image_dir, le, image_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads a trained model and predicts the top 3 classes for all images in a folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    # Define valid image extensions\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(valid_extensions):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Load and preprocess the image\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {filename}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = np.array(img, dtype='float32') / 255.0\n",
    "            img = np.expand_dims(img, axis=0)  # Add a batch dimension\n",
    "\n",
    "            # Make a prediction\n",
    "            preds_array = model.predict(img)\n",
    "            \n",
    "            # Get the indices of the top 3 predictions\n",
    "            top3_indices = np.argsort(preds_array[0])[-3:][::-1]\n",
    "            \n",
    "            # Inverse transform the indices to get the original rrcIDs\n",
    "            top3_labels = le.inverse_transform(top3_indices)\n",
    "            \n",
    "            # Get the corresponding confidence scores\n",
    "            top3_confidences = preds_array[0][top3_indices]\n",
    "            \n",
    "            result_entry = {\n",
    "                \"filename\": filename,\n",
    "                \"predictions\": []\n",
    "            }\n",
    "            \n",
    "            for label, confidence in zip(top3_labels, top3_confidences):\n",
    "                result_entry['predictions'].append({\n",
    "                    \"rrcID\": label,\n",
    "                    \"confidence\": f\"{confidence*100:.2f}%\"\n",
    "                })\n",
    "            \n",
    "            predictions.append(result_entry)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    # Path to the saved model file\n",
    "    model_path = \"./models/coin_classifier_rrcID.keras\"\n",
    "    \n",
    "    # Path to the folder containing the images you want to predict\n",
    "    batch_image_folder = \"./data/coins_to_classify\"\n",
    "    \n",
    "    # Path to your original CSV file\n",
    "    csv_file_path = \"./data/reece1.csv\"\n",
    "    \n",
    "    # --- Label Encoder Setup ---\n",
    "    # The LabelEncoder must be fitted on the same data as during training.\n",
    "    try:\n",
    "        df_labels = pd.read_csv(csv_file_path)\n",
    "        df_labels = df_labels.dropna(subset=['rrcID'])\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df_labels['rrcID'])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The CSV file '{csv_file_path}' was not found. Cannot load the label encoder.\")\n",
    "        exit()\n",
    "\n",
    "    # --- Run Batch Prediction ---\n",
    "    print(f\"Starting prediction for images in '{batch_image_folder}'...\")\n",
    "    results = predict_batch_of_images(model_path, batch_image_folder, le)\n",
    "\n",
    "    if results:\n",
    "        print(\"\\n--- Prediction Results ---\")\n",
    "        for result in results:\n",
    "            print(f\"File: {result['filename']}\")\n",
    "            for pred in result['predictions']:\n",
    "                print(f\"  - Predicted RRC ID: {pred['rrcID']} (Confidence: {pred['confidence']})\")\n",
    "            print() # Print a blank line for readability\n",
    "    else:\n",
    "        print(\"No eligible images found or predictions could not be made.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4da46c",
   "metadata": {},
   "source": [
    "These are going to be low confidence for that trained model due to the differences in the coin images from CRRO compared to the training dataset. So let's rerun that against the larger model that was trained and uploaded off the entire Reece Period 1 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613d2168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction for images in './data/coins_to_classify'...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "--- Prediction Results ---\n",
      "File: large_00624497_001.jpg\n",
      "  - Predicted RRC ID: rrc-412.1 (Confidence: 58.97%)\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 21.35%)\n",
      "  - Predicted RRC ID: rrc-544.13 (Confidence: 8.40%)\n",
      "\n",
      "File: 1937.158.67.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-443.1 (Confidence: 89.14%)\n",
      "  - Predicted RRC ID: rrc-544.20 (Confidence: 3.70%)\n",
      "  - Predicted RRC ID: rrc-458.1 (Confidence: 3.34%)\n",
      "\n",
      "File: 1974.26.48.rev.width175.jpg\n",
      "  - Predicted RRC ID: rrc-328.1 (Confidence: 73.07%)\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 17.51%)\n",
      "  - Predicted RRC ID: rrc-412.1 (Confidence: 5.85%)\n",
      "\n",
      "File: 1944.100.794.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-404.1 (Confidence: 50.13%)\n",
      "  - Predicted RRC ID: rrc-517.2 (Confidence: 31.77%)\n",
      "  - Predicted RRC ID: rrc-443.1 (Confidence: 9.36%)\n",
      "\n",
      "File: SUR-4C2E85_6874db2471a8b.jpg\n",
      "  - Predicted RRC ID: rrc-544.30 (Confidence: 8.70%)\n",
      "  - Predicted RRC ID: rrc-380.1 (Confidence: 6.40%)\n",
      "  - Predicted RRC ID: rrc-274.1 (Confidence: 4.70%)\n",
      "\n",
      "File: small_00630874_001.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 99.93%)\n",
      "  - Predicted RRC ID: rrc-422.1b (Confidence: 0.04%)\n",
      "  - Predicted RRC ID: rrc-544.13 (Confidence: 0.01%)\n",
      "\n",
      "File: sitnam.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 14.81%)\n",
      "  - Predicted RRC ID: rrc-474.5 (Confidence: 9.15%)\n",
      "  - Predicted RRC ID: rrc-378.1c (Confidence: 8.12%)\n",
      "\n",
      "File: large_00625064_001.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 71.84%)\n",
      "  - Predicted RRC ID: rrc-544.25 (Confidence: 27.22%)\n",
      "  - Predicted RRC ID: rrc-412.1 (Confidence: 0.49%)\n",
      "\n",
      "File: 1995.11.1650.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-244.1 (Confidence: 59.48%)\n",
      "  - Predicted RRC ID: rrc-323.1 (Confidence: 27.31%)\n",
      "  - Predicted RRC ID: rrc-544.26 (Confidence: 3.50%)\n",
      "\n",
      "File: 1947.2.175.rev.width175.jpg\n",
      "  - Predicted RRC ID: rrc-443.1 (Confidence: 58.57%)\n",
      "  - Predicted RRC ID: rrc-511.4a (Confidence: 26.18%)\n",
      "  - Predicted RRC ID: rrc-380.1 (Confidence: 10.06%)\n",
      "\n",
      "File: DenariusJuliusCasar270518JHF.jpg\n",
      "  - Predicted RRC ID: rrc-517.2 (Confidence: 70.04%)\n",
      "  - Predicted RRC ID: rrc-443.1 (Confidence: 29.89%)\n",
      "  - Predicted RRC ID: rrc-448.2a (Confidence: 0.04%)\n",
      "\n",
      "File: large_00630875_001.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 96.28%)\n",
      "  - Predicted RRC ID: rrc-544.25 (Confidence: 2.06%)\n",
      "  - Predicted RRC ID: rrc-422.1b (Confidence: 1.41%)\n",
      "\n",
      "File: large_01233074_001.jpg\n",
      "  - Predicted RRC ID: rrc-443.1 (Confidence: 44.65%)\n",
      "  - Predicted RRC ID: rrc-236.1a (Confidence: 16.11%)\n",
      "  - Predicted RRC ID: rrc-413.1 (Confidence: 9.76%)\n",
      "\n",
      "File: 1974.26.48.obv.width175.jpg\n",
      "  - Predicted RRC ID: rrc-286.1 (Confidence: 54.85%)\n",
      "  - Predicted RRC ID: rrc-372.1 (Confidence: 24.12%)\n",
      "  - Predicted RRC ID: rrc-494.24 (Confidence: 4.12%)\n",
      "\n",
      "File: large_00630874_001.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 99.67%)\n",
      "  - Predicted RRC ID: rrc-422.1b (Confidence: 0.24%)\n",
      "  - Predicted RRC ID: rrc-544.13 (Confidence: 0.05%)\n",
      "\n",
      "File: default.jpg\n",
      "  - Predicted RRC ID: rrc-354.1 (Confidence: 34.08%)\n",
      "  - Predicted RRC ID: rrc-442.1a (Confidence: 17.58%)\n",
      "  - Predicted RRC ID: rrc-544.26 (Confidence: 9.58%)\n",
      "\n",
      "File: large_00630755_001.jpg\n",
      "  - Predicted RRC ID: rrc-544.14 (Confidence: 99.65%)\n",
      "  - Predicted RRC ID: rrc-544.13 (Confidence: 0.34%)\n",
      "  - Predicted RRC ID: rrc-412.1 (Confidence: 0.01%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def predict_batch_of_images(model_path, image_dir, le, image_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads a trained model and predicts the top 3 classes for all images in a folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    # Define valid image extensions\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(valid_extensions):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Load and preprocess the image\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {filename}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            img = cv2.resize(img, image_size)\n",
    "            img = np.array(img, dtype='float32') / 255.0\n",
    "            img = np.expand_dims(img, axis=0)  # Add a batch dimension\n",
    "\n",
    "            # Make a prediction\n",
    "            preds_array = model.predict(img)\n",
    "            \n",
    "            # Get the indices of the top 3 predictions\n",
    "            top3_indices = np.argsort(preds_array[0])[-3:][::-1]\n",
    "            \n",
    "            # Inverse transform the indices to get the original rrcIDs\n",
    "            top3_labels = le.inverse_transform(top3_indices)\n",
    "            \n",
    "            # Get the corresponding confidence scores\n",
    "            top3_confidences = preds_array[0][top3_indices]\n",
    "            \n",
    "            result_entry = {\n",
    "                \"filename\": filename,\n",
    "                \"predictions\": []\n",
    "            }\n",
    "            \n",
    "            for label, confidence in zip(top3_labels, top3_confidences):\n",
    "                result_entry['predictions'].append({\n",
    "                    \"rrcID\": label,\n",
    "                    \"confidence\": f\"{confidence*100:.2f}%\"\n",
    "                })\n",
    "            \n",
    "            predictions.append(result_entry)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    # Path to the saved model file for the entire dataset\n",
    "    model_path = \"../models/coin_classifier_rrcID.keras\"\n",
    "    \n",
    "    # Path to the folder containing the images you want to predict\n",
    "    batch_image_folder = \"./data/coins_to_classify\"\n",
    "    \n",
    "    # Path to your entire CSV file from Reece 1\n",
    "    csv_file_path = \"../data/reece1.csv\"\n",
    "    \n",
    "    # --- Label Encoder Setup ---\n",
    "    # The LabelEncoder must be fitted on the same data as during training.\n",
    "    try:\n",
    "        df_labels = pd.read_csv(csv_file_path)\n",
    "        df_labels = df_labels.dropna(subset=['rrcID'])\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df_labels['rrcID'])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The CSV file '{csv_file_path}' was not found. Cannot load the label encoder.\")\n",
    "        exit()\n",
    "\n",
    "    # --- Run Batch Prediction ---\n",
    "    print(f\"Starting prediction for images in '{batch_image_folder}'...\")\n",
    "    results = predict_batch_of_images(model_path, batch_image_folder, le)\n",
    "\n",
    "    if results:\n",
    "        print(\"\\n--- Prediction Results ---\")\n",
    "        for result in results:\n",
    "            print(f\"File: {result['filename']}\")\n",
    "            for pred in result['predictions']:\n",
    "                print(f\"  - Predicted RRC ID: {pred['rrcID']} (Confidence: {pred['confidence']})\")\n",
    "            print() # Print a blank line for readability\n",
    "    else:\n",
    "        print(\"No eligible images found or predictions could not be made.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652c7b5",
   "metadata": {},
   "source": [
    "Slightly better results, but as PAS images are pretty variable and numbers so small, this won't be an amazing test. I would probably take the CRRO coins and reverse what I'm doing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
